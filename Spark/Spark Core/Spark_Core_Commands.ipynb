{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark Core Commands.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+jHzai4sf2bIZ7ECAKD5S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcestevezc/Cloudera/blob/master/Spark%20Core/Spark_Core_Commands.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_7ZbGRnDeUy",
        "colab_type": "text"
      },
      "source": [
        "### Create RDD from Local File\n",
        "\n",
        "You can use textFile spark context method to create RDD from local or HDFS file systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn44V1cfDQmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd = sc.textFile(\"file:////home/impadmin/test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jomkH1ArDmj1",
        "colab_type": "text"
      },
      "source": [
        "### Create RDD from HDFS File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uUJrMhiDvsb",
        "colab_type": "text"
      },
      "source": [
        "rdd = sc.textFile(\"hdfs:/localhost:8020/home/impadmin/test.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDgi80QFD-06",
        "colab_type": "text"
      },
      "source": [
        "## Basic Spark Transformations\n",
        "\n",
        "Transformations are Spark operation which will transform one RDD into another. Transformations will always create new RDD from original one.\n",
        "\n",
        "Below are some basic transformations in Spark:\n",
        "\n",
        "* map()\n",
        "* flatMap()\n",
        "* filter()\n",
        "* groupByKey()\n",
        "* reduceByKey()\n",
        "* sample()\n",
        "* union()\n",
        "* distinct()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD7X3E3cEP5I",
        "colab_type": "text"
      },
      "source": [
        "### map ()\n",
        "The “map” transformation apply lambda functions to all elements of the RDD and return new RDD.\n",
        "\n",
        "Convert all values in RDD to UPPER case. You can either create separate function to convert values to uppercase or write lambda function in map transformation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdYTMPlPD-UY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd1 = rdd.map(lambda x: x.upper(), rdd.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg8OHVG_Ehvu",
        "colab_type": "text"
      },
      "source": [
        "### flatMap()\n",
        "\n",
        "The “flatMap” transformation will return a new RDD by first applying a function to all elements of this RDD, and then flattening the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGTcCszTEg7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = lines.flatMap(lambda line: line.split(\" \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_1kDtFkFZbQ",
        "colab_type": "text"
      },
      "source": [
        "### filter()\n",
        "\n",
        "To remove the unwanted values, you can use a “filter” transformation which will return a new RDD containing only the elements that satisfy given condition(s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9jRPfA6Fh3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_values = ['ERTE','SADFS']\n",
        "rdd2 = rdd1.filter(lambda x: x not in remove_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X24UzhIMFvp_",
        "colab_type": "text"
      },
      "source": [
        "### groupByKey() and reduceByKey()\n",
        "\n",
        "You can apply groupByKey and reduceByKey transformations on key value pair RDD. The “groupByKey” will group the values for each key in the original RDD. It will create a new pair, where the original key corresponds to this collected group of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFNryC4fFvKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_tmp = rdd.map(lambda x: (x,1))\n",
        "rdd_grp = rdd_tmp.groupByKey()\n",
        "\n",
        "tuples = words.map(lambda word: (word, 1))\n",
        "counts = tuples.reduceByKey(lambda a,b: (a + b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfqI0TVoGjP0",
        "colab_type": "text"
      },
      "source": [
        "### sample()\n",
        "\n",
        "The “Sample” transformation will allow you to work on sample data set. The sample method will return a new RDD, containing a statistical sample of the original RDD. Given examples, select 20% (.2) of total original RDD values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCXDlGz2G-gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_sample = rdd.sample(False, .2, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLpmMlxNG-6K",
        "colab_type": "text"
      },
      "source": [
        "### union()\n",
        "\n",
        "You can combine content of two different RDD’s using “union” transformations. Result will be new RDD with all values from two RDD’s.\n",
        "\n",
        "rdd_sample1 = rdd.sample(False, .2, 4)\n",
        "rdd_sample2 = rdd.sample(False, .4, 4)\n",
        "union_samples = rdd_sample1.union(rdd_sample2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtFemU8OHH6L",
        "colab_type": "text"
      },
      "source": [
        "### distinct()\n",
        "\n",
        "You can select distinct elements from RDD using “distinct” transformation.Distinct transformation will create new RDD containing distinct elements from the original RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njd3HHAxHbm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_distinct = union_samples.distinct()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgR7wHSjHdot",
        "colab_type": "text"
      },
      "source": [
        "## Basic Spark Actions\n",
        "\n",
        "Actions in the spark are operations that provide non-RDD values. Actions will not create RDD like transformations.\n",
        "\n",
        "Below are some of the commonly used action in Spark.\n",
        "\n",
        "* collect()\n",
        "* take(n)\n",
        "* count()\n",
        "* max()\n",
        "* min()\n",
        "* sum()\n",
        "* variance()\n",
        "* stdev()\n",
        "* reduce()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ5fFSd0ICFO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Collect()\n",
        "Collect is simple spark action that allows you to return entire RDD content to drive program.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEOb_G5MICUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_distinct.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3uj7IrnIC3Y",
        "colab_type": "text"
      },
      "source": [
        "### take(n)\n",
        "\n",
        "You can use “take” action to display sample elements from RDD.\n",
        "You can check first 5 values from RDD using ‘take’ action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxQ9Y0OIIDAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mstNMdVWIDh_",
        "colab_type": "text"
      },
      "source": [
        "### count()\n",
        "The “count” action will count the number of elements in RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5aFoHAQIDrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_distinct.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLwDsa7OINNa",
        "colab_type": "text"
      },
      "source": [
        "### max()\n",
        "\n",
        "The “max” action will display the max elements from RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCmOypogIO7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_int.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "458qpG6CIPHA",
        "colab_type": "text"
      },
      "source": [
        "### min()\n",
        "\n",
        "The “min” action will display the min elements from RDD.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN40Ll0NIPO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_int.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-a8vGTnIPYP",
        "colab_type": "text"
      },
      "source": [
        "### variance()\n",
        "The “variance” action will display the variance of all elements from RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02qI52AhIPgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_int.variance()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNiob2euIPqH",
        "colab_type": "text"
      },
      "source": [
        "### stdev()\n",
        "The “stdev” action will display the stdev of all elements from RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJbySaKMIPwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_int.stdev ()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL2FqMnbIP43",
        "colab_type": "text"
      },
      "source": [
        "### Reduce()\n",
        "The “reduce” action takes the two elements as input from the RDD and then produces the output of the same type as that of the input elements.\n",
        "\n",
        "num_rdd = sc.parallelize(range(0,100))\n",
        "num_rdd.reduce(lambda x,y: x+y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz5yi2BUIQBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAfoek8YJHUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts.coalesce(1).saveAsTextFile(\"hdfs://localhost/user/cloudera/wordcount/outputDir\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}